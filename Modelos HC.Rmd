---
title: "Modelos de Heterocedasticidade Condicional"
author: "Luiz Araújo"
date: "03/04/2020"
output:
  pdf_document:
    keep_tex: yes
    latex_engine: xelatex
  word_document: default
---
# Será apresentado 7 modelos de HC para a série dos retornos da Vale. Primeiramente iremos analisar a série do retorno 
# e buscar o modelo ARMA que melhor se ajusta. E posteriormente, iremos buscar os modelos de HC que melhor se ajuste a série.
# Os modelos HC são Garch ( inovações gaussianas, t e skew t), IGARCH, GARCHM, EGARCH e TGARCH.

```{r echo=F, include =F,warning=F}
.packages = c("tidyquant", "tidyverse", "xtable", "stargazer", "highcharter", "quantmod",
              "dygraphs","tseries", "htmltools", "Quandl", "nycflights13", "magrittr",
              "discreteRV", "aTSA", "fGarch", "fUnitRoots", "vars", "MTS", "seasonal",
              "urca", "dynlm", "tbl2xts", "dlm", "AER", "nlme", "orcutt")
for (package in 1:length(.packages)) {
  suppressMessages(require(.packages[package], character.only = TRUE)) 
}

```




```{r echo=F, include =F}
quantmod::getSymbols.yahoo("VALE3.SA",env = .GlobalEnv,from=("2010-01-01"),to=("2020-04-18"))

vale <- VALE3.SA$VALE3.SA.Adjusted
vale <- as.numeric(vale[!is.na(vale),])
tdx <- index(remove_missing(VALE3.SA,na.rm=TRUE))

lvale <- log(vale)
dlvale<- diff(lvale)
dlvale <- dlvale[!is.na(dlvale)]
```




**Série Historica**

```{r}
rtn		= ts(vale, frequency = 252, start = c(2010, 1,1))
par (mfcol = c(1, 1))
plot (rtn, type = 'l', xlab = 'Tempo', ylab = 'Preço da VALE',main= c("Vale","2010-2020"))  
```


**Log do retorno da Vale**

```{r echo=F}
rtn		= ts(dlvale, frequency = 252, start = c(2010, 1,1))
par (mfcol = c(1, 1))
plot (rtn, type = 'l', xlab = 'Tempo', ylab = 'Retorno da VALE',main= c("Vale","2010-2020"))        
```

**Estatísticas**

```{r echo = F}
df <- data.frame(basicStats(vale),basicStats(dlvale))
colnames(df) <- c("VALE","Log do Retorno")
df
```




**Teste para a média da série**

O test t nos mostra que o retorno da vale foi estatísticamente igual a zero.
```{r }
t.test (dlvale) 
```

**Analise da FAC e FACP da série do retorno**

Existe algumas defasagens significantes. Portanto, devemos modelar a série do retorno antes de prosseguir com a modlagem da variância.
```{r }
par(mfcol=c(1,2))
acf(dlvale,lag=21)
pacf(dlvale,lag=21)
```

**Modelo proposto para o retorno: ARMA(4,6) com ajuste sazonal no período 15**
O modelo incialmente testado foi o ARMA(6,6) já que quase todas as 6 defasagens inicias da FACP e da FAC são significantes.

Após alguns testes, foi concluído que o modelo que melhor se ajusta ao retorno da série é:
```{r warning=FALSE}
c1 <- c(0,NA,0,NA,0,NA,0,NA,0,NA,NA)
m0=arima(dlvale,order=c(4,0,6),fixed=c1,include.mean=F,seasonal = list(order=c(1,0,0),period=15))
coeftest(m0)
```

**Análise dos resíduos de M0**

O teste de Ljung-Box mostra que os resíduos são não autocorrelacionados com suas defasagens. Ou seja, todas as informações que estava contida na série historica foram extraidas.
```{r }
tsdiag(m0,gof=21)  
resi0 = residuals (m0, standardize = T)
par (mfcol = c(1, 2))
acf (resi0, lag = 21)
pacf (resi0, lag = 21)
```

```{r echo=F, include=F}
archTest <- function (rtn, m = 10)
{
# Perform Lagrange Multiplier Test for ARCH effect of a time series
# rtn: time series
# m: selected AR order
#
y = (rtn - mean (rtn)) ^ 2
T = length (rtn)
atsq = y [(m + 1) : T]
x = matrix (0 , (T - m), m)
for (i in 1 : m)
   {
    x [ , i] = y[(m + 1 - i) : (T - i)]
   }
md = lm (atsq ~ x)
summary (md)
}
```



**Análise dos resíduos quadraticos de M0**

O teste arch e as defasagens dos resíduos quadraticos nos mostram que há dependência entre os resíduos. Portanto, a variância é heterocedastica e pode ser modelada.
```{r echo = TRUE }
archTest (resi0, 21)
par (mfcol = c(1, 2)) 							
acf (resi0^2, lag = 21)
pacf (resi0^2, lag = 21) 
```


## Modelos GARCH


**1.** **Modelo GARCH com inovações gaussianas**

$$
\sigma_t^2= \alpha_0 + \alpha_1a_{t-1}^2 +\beta_1\sigma_{t-1}^2; \hspace{10pt} \epsilon_t \sim N(0,1)
$$

Todos os coefs do GARCH(1,1) com inovações gaussianas foram significantes. Mas é possível verificar que o Teste de Jarque-Bera para os resíduos padronizados não foi aceito.
```{r }
m1 <- garchFit(~garch(1,1),data=resi0, trace= F,include.mean = F)
summary(m1) 

```


$$
\sigma_t^2= 0.0000  + 0.0539a_{t-1}^2 +0.9374\sigma_{t-1}^2
$$

**Análise dos resíduos quadraticos de M1:**

O arch teste mostrou que Aceitamos H0, ou seja, os resíduos não são autocorrelacionados.Portanto, todas as informações contidas na série foram extraidas.
```{r}
resi1 = residuals (m1, standardize = T)
archTest (resi1, 21)
par (mfcol = c(1, 2)) 							
acf (resi1^2, lag = 21)
pacf (resi1^2, lag = 21)
```




**Análise das inovações:**

Podemos verificar que as inovações se comportam como um ruído branco. Já que não há defasagens significantes.
```{r}
par (mfcol = c(1, 2)) 							
acf (resi1, lag = 21)
pacf (resi1, lag = 21)
```



**2.** **Modelo GARCH com inovações t**


$$
\sigma_t^2= \alpha_0 + \alpha_1 a_{t-1}^2 +\beta_1\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim t^*_{gl}
$$

Todos os coefs do GARCH(1,1) com inovações com distribuição T de Student foram significantes.
```{r }
m2 <- garchFit(~garch(1,1),data=resi0, trace= F, include.mean = F, cond.dist = "std")
summary(m2) 
```

$$
\sigma_t^2= 0.0000 + 0.0561 a_{t-1}^2 +0.9359\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim t^*_{6.7217 }
$$


**Análise dos resíduos quadraticos de M2:**

É possível verificar que os resíduos quadraticos não são autocorrelacionados. 
```{r}
resi2 = residuals (m2, standardize = T)
archTest (resi2, 20)
par (mfcol = c(1, 2)) 							
acf (resi2^2, lag = 21)
pacf (resi2^2, lag = 21)
```

**Análise das inovações:**

Podemos verificar que as inovações se comportam como um ruído branco.
```{r}
par (mfcol = c(1, 2)) 							
acf (resi2, lag = 21)
pacf (resi2, lag = 21)
```


**3.** **Modelo GARCH com inovações t e com assimetria**

$$
\sigma_t^2= \alpha_0 + \alpha_1 a_{t-1}^2 +\beta_1\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim t^*_{sk,gl}
$$

Todos os coefs do modelo GARCH(1,1) foram significantes.

```{r }
m3 <- garchFit(~garch(1,1),data=resi0, trace= F, include.mean = F, cond.dist = "sstd")
summary(m3)
```

$$
\sigma_t^2= 0.0000  + 0.0561 a_{t-1}^2 +0.9360\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim t^*_{0.9886,6.7162}
$$


**Análise dos resíduos quadraticos de M3:**

Aceitamos H0 do arch teste, ou seja, não há correlação entre os resíduos.
```{r }
resi3 = residuals (m3, standardize = T)
archTest (resi3, 20)
par (mfcol = c(1, 2)) 							
acf (resi3^2, lag = 21)
pacf (resi3^2, lag = 21)
```

**Análise das inovações:**

Podemos verificar que as inovações se comportam como um ruído branco.
```{r}
par (mfcol = c(1, 2)) 							
acf (resi3, lag = 21)
pacf (resi3, lag = 21)
```


**Volatilidade dos modelos**

```{r echo=F }
# Volatilidade dos modelos GARCH
v1 = volatility (m1) 
v2 = volatility (m2) 
v3 = volatility (m3) 

vol1 = ts (v1, frequency = 252, start = c(2010, 1,1))
vol2 = ts (v2, frequency = 252, start = c(2010, 1,1))
vol3 = ts (v3, frequency = 252, start = c(2010, 1,1))

par (mfcol = c(3, 1))  							
plot (vol1, xlab = 'year', ylab = 'Volatilidade norm', type = 'l')
plot (vol2, xlab = 'year', ylab = 'Volatilidade std', type = 'l')
plot (vol3, xlab = 'year', ylab = 'Volatilidade sstd', type = 'l')
```

**Intervalo de Confiança**

```{r echo=F}
par (mfcol = c(1, 1))
mu = m1@fit$coef[1]
upp = mu + 2 * v1
low = mu - 2 * v1
tdx <- index(remove_missing(VALE3.SA,na.rm=TRUE))
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),
      main="GARCH norm")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')


mu = m2@fit$coef[1]
upp = mu + 2 * v2
low = mu - 2 * v2
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),
      main="GARCH std")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')


mu = m3@fit$coef[1]
upp = mu + 2 * v3
low = mu - 2 * v3
plot (tdx[2:2540], resi0,xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),
      main="GARCH sstd")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')
par (mfcol = c(1, 1))
```


## Modelo IGARCH
```{r echo=F, include = F}
"Igarch" <- function(rtn,include.mean=F,volcnt=F){
# Estimation of a Gaussian IGARCH(1,1) model.
# rtn: return series 
# include.mean: flag for the constant in the mean equation.
# volcnt: flag for the constant term of the volatility equation.
#### default is the RiskMetrics model
#
Idata <<- rtn
Flag <<- c(include.mean,volcnt)
#
Mean=mean(Idata); Var = var(Idata); S = 1e-6
if((volcnt)&&(include.mean)){
params=c(mu = Mean,omega=0.1*Var,beta=0.85)
lowerBounds = c(mu = -10*abs(Mean), omega= S^2, beta= S)
upperBounds = c(mu = 10*abs(Mean), omega = 100*Var, beta = 1-S)
}
if((volcnt)&&(!include.mean)){
params=c(omega=0.1*Var, beta=0.85)
lowerBounds=c(omega=S^2,beta=S)
upperBounds=c(omega=100*Var,beta=1-S)
}
#
if((!volcnt)&&(include.mean)){
params=c(mu = Mean, beta= 0.8)
lowerBounds = c(mu = -10*abs(Mean), beta= S)
upperBounds = c(mu = 10*abs(Mean), beta = 1-S)
}
if((!volcnt)&&(!include.mean)){
params=c(beta=0.85)
lowerBounds=c(beta=S)
upperBounds=c(beta=1-S)
}
# Step 3: set conditional distribution function:
igarchDist = function(z,hh){dnorm(x = z/hh)/hh}
# Step 4: Compose log-likelihood function:
igarchLLH = function(parm){
include.mean=Flag[1]
volcnt=Flag[2]
mu=0; omega = 0
if((include.mean)&&(volcnt)){
my=parm[1]; omega=parm[2]; beta=parm[3]}
if((!include.mean)&&(volcnt)){
omega=parm[1];beta=parm[2]}
if((!include.mean)&&(!volcnt))beta=parm[1]
if((include.mean)&&(!volcnt)){mu=parm[1]; beta=parm[2]}
#
z = (Idata - mu); Meanz = mean(z^2)
e= omega + (1-beta)* c(Meanz, z[-length(Idata)]^2)
h = filter(e, beta, "r", init=Meanz)
hh = sqrt(abs(h))
llh = -sum(log(igarchDist(z, hh)))
llh
}
# Step 5: Estimate Parameters and Compute Numerically Hessian:
fit = nlminb(start = params, objective = igarchLLH,
lower = lowerBounds, upper = upperBounds)
##lower = lowerBounds, upper = upperBounds, control = list(trace=3))
epsilon = 0.0001 * fit$par
cat("Estimates: ",fit$par,"\n")
npar=length(params)
Hessian = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = fit$par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
Hessian[i, j] = (igarchLLH(x1)-igarchLLH(x2)-igarchLLH(x3)+igarchLLH(x4))/
(4*epsilon[i]*epsilon[j])
}
}
cat("Maximized log-likehood: ",igarchLLH(fit$par),"\n")
# Step 6: Create and Print Summary Report:
se.coef = sqrt(diag(solve(Hessian)))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate",
" Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)

if((include.mean)&&(volcnt)){
mu=fit$par[1]; omega=fit$par[2]; beta = fit$par[3]
}
if((include.mean)&&(!volcnt)){
mu = fit$par[1]; beta = fit$par[2]; omega = 0
}
if((!include.mean)&&(volcnt)){
mu=0; omega=fit$par[1]; beta=fit$par[2]
}
if((!include.mean)&&(!volcnt)){
mu=0; omega=0; beta=fit$par[1]
}
z=Idata-mu; Mz = mean(z^2)
e= omega + (1-beta)*c(Mz,z[-length(z)]^2)
h = filter(e,beta,"r",init=Mz)
vol = sqrt(abs(h))

Igarch <- list(par=fit$par,volatility = vol)
}



```

No modelo IGARCH, partimos do pressuposto de que $\alpha_1 + \beta1 = 1$. Portanto, sugere que a série apresenta raíz unitária. Não é estacionaria.

$$
\sigma_t^2= \alpha_0 + (1-\beta_1)a_{t-1}^2 +\beta_1\sigma_{t-1}^2,\hspace{12pt} \epsilon_t \sim N(0,1)
$$

IGARCH(1,1) com inovações Gaussianas. O coef Beta é estatisticamente significante.
```{r}
m5 = Igarch (resi0)
resi5 = resi0 / m5$volatility

```




$$
\sigma_t^2=  0.0421 a_{t-1}^2 +0.9579 \sigma_{t-1}^2 
$$



**Análise dos resíduos quadraticos de M5:**

De acordo o arch teste e a análise da FAC e FACP não há autocorrelação entre as defasagens dos resíduos quadraticos.
```{r echo=F}
archTest (resi5, 21)
par (mfcol = c(1, 2))
acf (resi5^2, lag = 21)
pacf (resi5^2, lag = 21)
```




**Análise das inovações:**

A FAC e a FACP nos mostram que apenas a defasagem 4 é significante. Talvez ela seja um outlier
```{r}
par (mfcol = c(1, 2)) 							
acf (resi5, lag = 21)
pacf (resi5, lag = 21)
```

**Intervalo de COnfiança**

```{r echo=F}
# Previsão com os Intervalos
v5 = m5$volatility 
par (mfcol = c(1, 1))
mu = 0
upp = mu + 2 * v5
low = mu - 2 * v5
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),main="IGARCH(1,1)")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')

```


## Modelo GARCH-M
```{r echo=F,include= F}
"garchM" <- function(rtn,type=1){
# Estimation of a Gaussian GARCH(1,1)-M model.
##### The program uses GARCH(1,1) results as initial values.
# rtn: return series 
# type = 1 for Variance-in-mean
#      = 2 for volatility-in-mean
#      = 3 for log(variance)-in-mean
#
if(is.matrix(rtn))rtn=c(rtn[,1])
garchMdata <<- rtn
# obtain initial estimates
m1=garch11FIT(garchMdata)
est=as.numeric(m1$par); v1=m1$ht  ## v1 is sigma.t-square
Mean=est[1]; cc=est[2]; ar=est[3]; ma=est[4]; S=1e-6
if(type==2)v1=sqrt(v1)
if(type==3)v1=log(v1)
#### Obtain initial estimate of the parameters for the mean equation
m2=lm(rtn~v1)
Cnst=as.numeric(m2$coefficients[1])
gam=as.numeric(m2$coefficients[2])
params=c(mu=Cnst,gamma=gam, omega=cc, alpha=ar,beta=ma)
lowBounds=c(mu=-5*abs(Mean),gamma=-20*abs(gam), omega=S, alpha=S, beta=ma*0.6)
uppBounds=c(mu=5*abs(Mean),gamma=100*abs(gam), omega=cc*5 ,alpha=3*ar,beta=1-S)
### Pass model information via defining global variable
Vtmp <<- c(type,v1[1])
#
fit=nlminb(start = params, objective= glkM, lower=lowBounds, upper=uppBounds)
##,control=list(trace=3,rel.tol=1e-5))
epsilon = 0.0001 * fit$par
npar=length(params)
Hessian = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = fit$par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
Hessian[i, j] = (glkM(x1)-glkM(x2)-glkM(x3)+glkM(x4))/
(4*epsilon[i]*epsilon[j])
}
}
cat("Maximized log-likehood: ",-glkM(fit$par),"\n")
# Step 6: Create and Print Summary Report:
se.coef = sqrt(diag(solve(Hessian)))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate",
" Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)

m3=ResiVol(fit$par)

garchM <- list(residuals=m3$residuals,sigma.t=m3$sigma.t)
}

glkM = function(pars){
rtn <- garchMdata
mu=pars[1]; gamma=pars[2]; omega=pars[3]; alpha=pars[4]; beta=pars[5]
type=Vtmp[1]
nT=length(rtn)
# use conditional variance
if(type==1){
ht=Vtmp[2]
et=rtn[1]-mu-gamma*ht
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept = rtn[i]-mu-gamma*sig2t
at=c(at,ept)
ht=c(ht,sig2t)
}
}
# use volatility
if(type==2){
ht=Vtmp[2]^2
et=rtn[1]-mu-gamma*Vtmp[2]
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept=rtn[i]-mu-gamma*sqrt(sig2t)
at=c(at,ept)
ht=c(ht,sig2t)
}
}
# use log(variance)
if(type==3){
ht=exp(Vtmp[2])
et=rtn[1]-mu-gamma*Vtmp[2]
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept=rtn[i]-mu-gamma*log(abs(sig2t))
at=c(at,ept)
ht=c(ht,sig2t)
}
}
#
hh=sqrt(abs(ht))
glk=-sum(log(dnorm(x=at/hh)/hh))

glk
}


ResiVol = function(pars){
rtn <- garchMdata
mu=pars[1]; gamma=pars[2]; omega=pars[3]; alpha=pars[4]; beta=pars[5]
type=Vtmp[1]
nT=length(rtn)
# use conditional variance
if(type==1){
ht=Vtmp[2]
et=rtn[1]-mu-gamma*ht
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept = rtn[i]-mu-gamma*sig2t
at=c(at,ept)
ht=c(ht,sig2t)
}
}
# use volatility
if(type==2){
ht=Vtmp[2]^2
et=rtn[1]-mu-gamma*Vtmp[2]
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept=rtn[i]-mu-gamma*sqrt(sig2t)
at=c(at,ept)
ht=c(ht,sig2t)
}
}
# use log(variance)
if(type==3){
ht=exp(Vtmp[2])
et=rtn[1]-mu-gamma*Vtmp[2]
at=c(et)
for (i in 2:nT){
sig2t=omega+alpha*at[i-1]^2+beta*ht[i-1]
ept=rtn[i]-mu-gamma*log(abs(sig2t))
at=c(at,ept)
ht=c(ht,sig2t)
}
}
#

ResiVol <- list(residuals=at,sigma.t=sqrt(ht))
}

garch11FIT = function(x){
# Step 1: Initialize Time Series Globally:
tx <<- x
# Step 2: Initialize Model Parameters and Bounds:
Mean = mean(tx); Var = var(tx); S = 1e-6
params = c(mu = Mean, omega = 0.1*Var, alpha = 0.1, beta = 0.8)
lowerBounds = c(mu = -10*abs(Mean), omega = S^2, alpha = S, beta = S)
upperBounds = c(mu = 10*abs(Mean), omega = 100*Var, alpha = 1-S, beta = 1-S)
# Step 3: Set Conditional Distribution Function:
garchDist = function(z, hh) { dnorm(x = z/hh)/hh }
# Step 4: Compose log-Likelihood Function:
garchLLH = function(parm) {
mu = parm[1]; omega = parm[2]; alpha = parm[3]; beta = parm[4]
z = tx-mu; Mean = mean(z^2)
# Use Filter Representation:
e = omega + alpha * c(Mean, z[-length(tx)]^2)
h = filter(e, beta, "r", init = Mean)
hh = sqrt(abs(h))
llh = -sum(log(garchDist(z, hh)))
llh }
#####print(garchLLH(params))
# Step 5: Estimate Parameters and Compute Numerically Hessian:
fit = nlminb(start = params, objective = garchLLH,
lower = lowerBounds, upper = upperBounds)
#
est=fit$par
# compute the sigma.t^2 series
z=tx-est[1]; Mean=mean(z^2)
e=est[2]+est[3]*c(Mean,z[-length(tx)]^2)
h=filter(e,est[4],"r",init=Mean)

garch11Fit <- list(par=est,ht=h)
}


```

$$
r_t = \mu +c\sigma^2_t+a_t
$$

O termo $c$ é conhecido como prêmio de risco. E sugere que uma maior volatilidade impacta positivamente o retorno. Remete a ideia de que uma maior volatilidade é compensada por um maior retorno.

$$
\sigma_t^2= \alpha_0 + \alpha_1 a_{t-1}^2 +\beta_1\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim N(0,1)
$$

GARCHM(1,1) com inovações Gaussianas
```{r}
m6 = garchM (dlvale, type = 2)
```



$$
r_t = \mu +a_t
$$

Os coeficientes estimados sugerem que o parâmetro $c$ não é significante. Ou seja, o modelo é semelhante ao GARCH(1,1).

$$
\sigma_t^2= 0.0000+ 0.0518 a_{t-1}^2 +0.9404 \sigma_{t-1}^2 
$$


**Análise dos resíduos quadraticos de M6:**

Rejeitamos H0 do arch teste e a FAC e FACP nos mostra que há autocorrelação entre os resíduos quadraticos.
```{r}
resi6 = m6$residuals
archTest (resi6, 20)
par (mfcol = c(1, 2))
acf (resi6^2, lag = 24)
pacf (resi6^2, lag = 24) 
```


**Análise das inovações:**

As inovações não se comportam como um ruído branco.
```{r}
par (mfcol = c(1, 2)) 							
acf (resi6, lag = 24)
pacf (resi6, lag = 24)
```




**Intervalo de Confiança**

```{r echo=F}
# Previsão com os Intervalos
v6 = m6$sigma.t	
par (mfcol = c(1, 1))
mu = 0
upp = mu + 2 * v6
low = mu - 2 * v6
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6), main="MGARCH")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')

```

## Modelo EGARCH
```{r echo=F, include=F}
"Egarch" <- function(rtn){
# Estimation of an EGARCH(1,1) model. Assume normal innovations
# rtn: return series 
#
write(rtn,file='tmp.txt',ncol=1)
# obtain initial estimates
mu=mean(rtn)
par=c(mu,0.1,0.1,0.1,0.7)
#
#
#mm=optim(par,glk,method="Nelder-Mead",hessian=T)
low=c(-10,-5,0,-1,0)
upp=c(10,5,1,0,1)
mm=optim(par,glk,method="L-BFGS-B",hessian=T,lower=low,upper=upp)
## Print the results
par=mm$par
H=mm$hessian
Hi = solve(H)
cat(" ","\n")
cat("Estimation results of EGARCH(1,1) model:","\n")
cat("estimates: ",par,"\n")
se=sqrt(diag(Hi))
cat("std.errors: ",se,"\n")
tra=par/se
cat("t-ratio: ",tra,"\n")
# compute the volatility series and residuals
ht=var(rtn)
T=length(rtn)
if(T > 40)ht=var(rtn[1:40])
at=rtn-par[1]
for (i in 2:T){
eptm1=at[i-1]/sqrt(ht[i-1])
lnht=par[2]+par[3]*(abs(eptm1)+par[4]*eptm1)+par[5]*log(ht[i-1])
sig2t=exp(lnht)
ht=c(ht,sig2t)
}
sigma.t=sqrt(ht)
Egarch <- list(residuals=at,volatility=sigma.t)
}

glk <- function(par){
rtn=read.table("tmp.txt")[,1]
glk=0
ht=var(rtn)
T=length(rtn)
if(T > 40)ht=var(rtn[1:40])
at=rtn[1]-par[1]
for (i in 2:T){
ept=rtn[i]-par[1]
at=c(at,ept)
eptm1=at[i-1]/sqrt(ht[i-1])
lnht=par[2]+par[3]*(abs(eptm1)+par[4]*eptm1)+par[5]*log(ht[i-1])
sig2t=exp(lnht)
ht=c(ht,sig2t)
glk=glk + 0.5*(lnht + ept^2/sig2t)
}
glk
}
```

$$
(1-\alpha \beta) ln(\sigma_t^2)= (1-\alpha)\alpha_0 +g(\epsilon_{t-1}), \hspace{12pt} \epsilon_t \sim N(0,1)
$$
O modelo EGARCH tenta capturar o *Leverage Effect*. Ou seja, tenta capturar a assimentria na volatilidade. Já que os fatos estilizados sugerem que a volatilidade quando há choques negativos é maior do que a volatilidade quando os choques são positivos.

$$
(1-\alpha \beta) ln(\sigma_t^2)= \left \{\begin{array}{l}\alpha_*+(\gamma+\theta)\epsilon_{t-1} \hspace{27pt} \epsilon_{t-1} \ge 0 \\\alpha_*+(\gamma-\theta)(-\epsilon_{t-1}) \hspace{12pt} \epsilon_{t-1} < 0 \end{array}\right.
$$

EGARCH(1,1) com inovações gaussianas
```{r warning=FALSE}
m7 = Egarch(resi0)
```



**Análise dos resíduos quadraticos de M7:**

Aceitamos H0 do arch teste e as defasagens da FAC e da FACP não são significantes. Tudo indica que os as defasagens dos resíduos quadraticos não são significnates.
```{r}
    
resi7 = m7$residuals / m7$volatility 
archTest (resi7, 21)
par (mfcol = c(1, 2))
acf (resi7^2, lag = 21)
pacf (resi7^2, lag = 21) 
```


**Análise das inovações:**

As inovações se comportam como um ruído branco.

```{r}
par (mfcol = c(1, 2)) 							
acf (resi7, lag = 21)
pacf (resi7, lag = 21)

```

**Intervalo de Confiança**

```{r echo=F}
# Previsão com os Intervalos
v7 = m7$volatility 
par (mfcol = c(1, 1))
mu =0
upp = mu + 2 * v7
low = mu - 2 * v7
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),main="EGARCH(1,1)")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')
```

## Modelo TGARCH
```{r echo=F,include = F}
Tgarch11 = function(x,cond.dist="norm")
{
# Estimation of TGARCH(1,1) model with Gaussian or Student-t innovations
# Step 1: Initialize Time Series Globally:
Tx <<- x
# Step 2: Initialize Model Parameters and Bounds:
Meanx = mean(Tx); Varx = var(Tx); S = 1e-6
if(cond.dist=="std"){
params = c(mu = Meanx, omega = 0.1*Varx, alpha = 0.1, gam1= 0.02, beta = 0.81, shape=6)
lowerBounds = c(mu = -10*abs(Meanx), omega = S^2, alpha = S, gam1=S, beta = S, shape=3)
upperBounds = c(mu = 10*abs(Meanx), omega = 100*Varx, alpha = 1-S, gam1 = 1-S, beta = 1-S, shape=30)
}
else{
params = c(mu = Meanx, omega = 0.1*Varx, alpha = 0.1, gam1= 0.02, beta = 0.81)
lowerBounds = c(mu = -10*abs(Meanx), omega = S^2, alpha = S, gam1=S, beta = S)
upperBounds = c(mu = 10*abs(Meanx), omega = 10*Varx, alpha = 1-S, gam1 = 1-S, beta = 1-S)
}
# Step 3: Set Conditional Distribution Function:
garchDist = function(z, hh, cond.dist, nu1) { 
if(cond.dist=="std"){LL=dstd(x = z/hh, nu=nu1)/hh}
else{
LL=dnorm(x = z/hh)/hh }
LL
}
# Step 4: Compose log-Likelihood Function:
garchLLH = function(parm) {
mu = parm[1]; omega = parm[2]; alpha = parm[3]; gam1=parm[4]; beta = parm[5]
shape = 0; 
if(length(parm)==6){
shape=parm[6]
cond.dist="std"
}
else
{cond.dist="norm"}
z = (Tx-mu); Mean = mean(z^2)
zm1=c(0,z[-length(z)])
idx=seq(zm1)[zm1 < 0]; z1=rep(0,length(z)); z1[idx]=1
# Use Filter Representation:
e = omega + alpha * c(Mean, z[-length(z)]^2) + gam1*z1*c(Mean,z[-length(z)]^2)
h = filter(e, beta, "r", init = Mean)
hh = sqrt(abs(h))
llh = -sum(log(garchDist(z, hh, cond.dist, shape)))
llh }
# Step 5: Estimate Parameters and Compute Numerically Hessian:
fit = nlminb(start = params, objective = garchLLH,
lower = lowerBounds, upper = upperBounds) ### control = list(trace=3))
epsilon = 0.0001 * fit$par
npar=length(params)
Hessian = matrix(0, ncol = npar, nrow = npar)
for (i in 1:npar) {
for (j in 1:npar) {
x1 = x2 = x3 = x4  = fit$par
x1[i] = x1[i] + epsilon[i]; x1[j] = x1[j] + epsilon[j]
x2[i] = x2[i] + epsilon[i]; x2[j] = x2[j] - epsilon[j]
x3[i] = x3[i] - epsilon[i]; x3[j] = x3[j] + epsilon[j]
x4[i] = x4[i] - epsilon[i]; x4[j] = x4[j] - epsilon[j]
Hessian[i, j] = (garchLLH(x1)-garchLLH(x2)-garchLLH(x3)+garchLLH(x4))/
(4*epsilon[i]*epsilon[j])
}
}
cat("Log likelihood at MLEs: ","\n")
print(-garchLLH(fit$par))
# Step 6: Create and Print Summary Report:
se.coef = sqrt(diag(solve(Hessian)))
tval = fit$par/se.coef
matcoef = cbind(fit$par, se.coef, tval, 2*(1-pnorm(abs(tval))))
dimnames(matcoef) = list(names(tval), c(" Estimate",
" Std. Error", " t value", "Pr(>|t|)"))
cat("\nCoefficient(s):\n")
printCoefmat(matcoef, digits = 6, signif.stars = TRUE)
# compute output
est=fit$par
mu = est[1]; omega = est[2]; alpha = est[3]; gam1=est[4]; beta = est[5]
z=(Tx-mu); Mean = mean(z^2)
zm1=c(0,z[-length(z)])
idx=seq(zm1)[zm1 < 0]; z1=rep(0,length(z)); z1[idx]=1
e = omega + alpha * c(Mean, z[-length(z)]^2) + gam1*z1*c(Mean,z[-length(z)]^2)
h = filter(e, beta, "r", init = Mean)
sigma.t = sqrt(abs(h))

Tgarch11 <- list(residuals = z, volatility = sigma.t, par=est)
}

```

$$
\sigma_t^2= \alpha_0 + (\alpha_1+ \gamma _1N_{t-1})a_{t-1}^2 +\beta_1\sigma_{t-1}^2, \hspace{12pt} \epsilon_t \sim N(0,1)
$$
O TGARCH também tenta a cpturar o *Leverage Effect*.
 
$$
N_{t-1}= \left \{\begin{array}{l}1 \hspace{12pt}se \hspace{12pt} a_{t-1} < 0 \\0 \hspace{12pt} se \hspace{12pt} a_{t-1} \ge 0 \end{array}\right.
$$

TGARCH(1,1)  com inovações gaussianas

```{r}
m8 = Tgarch11 (resi0)
```





**Análise dos resíduos quadraticos de M8:**

Não há autocorrelação entres os resíduos quadraticos e aceitamos H0 do arch teste.


```{r}
resi8 = m8$residuals / m8$volatility 
archTest (resi8, 20)
par (mfcol = c(1, 2))
acf (resi8^2, lag = 24)
pacf (resi8^2, lag = 24)
```


**Análise das inovações:**

Inovações se comportam como um ruído branco.

```{r}
par (mfcol = c(1, 2)) 							
acf (resi8, lag = 21)
pacf (resi8, lag = 21)
```


**Intervalo de Confiança**

```{r echo=F}
# Previsão com os Intervalos
v8 = m8$volatility 
par (mfcol = c(1, 1))
mu = m8$par[1]
upp = mu + 2 * v8
low = mu - 2 * v8
plot (tdx[2:2540], resi0, xlab = 'Tempo', ylab = 'Retorno da Vale', type = 'l', ylim = c(-0.6, 0.6),main="TGARCH(1,1)")
lines (tdx[2:2540], upp, lty = 2, col = 'red')
lines (tdx[2:2540], low, lty = 2, col = 'red')
abline (h = c(mu), col = 'red')
```

## Comparação dos Modelos

```{r echo= F}
par (mfcol = c(2, 2))
plot (tdx[2:2540], v5, xlab = 'Tempo', ylab = 'volatility', type = 'l', ylim = c(-0.02, 0.09))
title (main = '(a) IGarch(1,1)')
plot (tdx[2:2540], v6, xlab = 'Tempo', ylab = 'volatility', type = 'l', ylim = c(-0.02, 0.09))
title (main = '(b) GarchM(1,1)')
plot (tdx[2:2540], v7, xlab = 'Tempo', ylab = 'volatility', type = 'l', ylim = c(-0.02, 0.09))
title (main = '(c) EGarch(1,1)') 
plot (tdx[2:2540], v8, xlab = 'Tempo', ylab = 'volatility', type = 'l', ylim = c(-0.02, 0.09))
title (main = '(c) TGarch(1,1)') 
```


**Criterio de Informação (AIC)**

```{r echo=F}
print(paste0("GARCH (norm): ",round(m1@fit$ics[1],5)))
print(paste0("GARCH (std): ",round(m2@fit$ics[1],5)))
print(paste0("GARCH (sstd): ",round(m3@fit$ics[1],5)))
```

**Correlação**

```{r echo=F}
df.cor <- data.frame(cor(cbind(v1,v2,v3,v5,v6,v7,v8)),row.names = c("GARCH (norm)","GARCH (std)",
                "GARCH (sstd)","IGARCH","GARCHM","EGARCH","TGARCH"))

colnames(df.cor) <- c("GARCH (norm)","GARCH (std)",
                "GARCH (sstd)","IGARCH","GARCHM","EGARCH","TGARCH")
df.cor
```



```{r}
hist.FD(resi1,main='Residuos padronizados do Modelo 1')
hist.FD(resi2,main='Residuos padronizados do Modelo 2')
hist.FD(resi3,main='Residuos padronizados do Modelo 3')

```
